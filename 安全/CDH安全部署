方案内容：
1 CDH数据安全方案设计
2 数据安全方案实施
3 数据权限划分要点
4 安全方案实施对现有集群的影响
5 安全方案的运维
6 其他可能的安全需求

1 方案准备说明
方案基于CD6.3进行设计；原则上以实现数据授权为目标，兼顾运维需求。
前置条件：
1）	因为是内网，可以不做通信加密（TSL）；
2）	在满足基本权限要求的前提下，可以考虑使用LDAP做用户管理。
3）	可以考虑使用集成的开源工具，如FreeIPA。
2 安全方案需求
1）	实现细粒度的权限管控；
2）	数据对象的通配符筛选；
3）	CDH数据接口尽可能覆盖；
4）	合理的运维操作与支持；
5）	体系的高可用性；
3 安全方案设计
3.1 方案设计
采用MIT Kerberos + Sentry + openLADP 方案。Kerberos实现所用用户以及服务间的身份认证，LDAP实现用户管理，Sentry用来做授权。
3.2 高可用设计
Sentry本身支持高可用部署，可以部署两个Sentry Server；
KDC也支持主备部署，安装时默认采用2分钟的同步间隔。多个KDC可同时作为备份，当MasterKDC 失败后，从KDC将自动提供认证服务，此时对已有的账户认证不受影响，但是不能做新增操作。
所有对KDC的所作都记录在MasterKDC节点，这个操作需要手动同步到其他从KDC节点。
Kadmin进程提供了远程kadmin服务，若此服务失败，不能通过管理客户端kadmin进行管理命令操作，但是仍然可以在Master本地启动kadmin.local 进程进行操作，同时，数据会直接写入本地数据库文件中，不受krb5kdc进程影响。  

3.3安全方案对现有HDFS的影响
1）采用安全方案时，HDFS开启权限认证模式，访问HDFS文件需要匹配HDFS的访问控制权限。
2）Sentry会同步当前HDFS的ACL信息，
Sentry权限设计只对HiveSQL/impala有效， Sentry也可以对HDFS特定目录生效（对Hive SQL生效，通过其他方式访问HDFS目录的，只能通过HDFS ACL配置权限）。
3）所有的客户端访问HDFS/Hive/impala时需要提前初始化kerberos票据。
4）Sentry授权只能对用户组授权，授权最细粒度为列Column。
5）Hue的用户与Linux用户是按名称对应的，但是需要手动创建，不能自动识别。
6）所有的Hadoop客户端都需要做Kerberos适配。

4 安全方案部署实施
4.1 测试环境 
准备测试账户
Kerberos 管理账号：admin ： AAS@123
Cloudera Kerberos管理员账号：  cloudera-scm  :  AAS@123
HDFS超级账户：hdfs：hdfs
Hive超级账户： hvie：hive
Impala超级账户：impala：impala
测试账号;  tpc ： tpc
测试环境地址
CDH 地址：http://172.19.2.184:7180/cmf/home
Kerberos 地址： Master: cloudera02.AAS.com   备：cloudera03.AAS.com
OpenLDAP地址：cloudera01.AAS.com
4.2 Kerberos部署
参考文档
安装链接:
https://www.jianshu.com/p/544aeacc803b
排错链接;
https://www.cnblogs.com/barneywill/p/10398663.html
参数解释
https://www.cnblogs.com/wn1m/p/10700466.html
4.2.1 在cloudera03节点部署KDC
##执行命令
yum -y install krb5-server krb5-libs krb5-auth-dialog1 krb5-workstation
4.2.2配置kdc.conf 文件/var/kerberos/krb5kdc/kdc.conf
vi /var/kerberos/krb5kdc/kdc.conf
[kdcdefaults]
kdc_ports = 88
kdc_tcp_ports = 88
[realms]
AAS.COM = {
#master_key_type = aes256-cts
acl_file = /var/kerberos/krb5kdc/kadm5.acl
dict_file = /usr/share/dict/words
admin_keytab = /var/kerberos/krb5kdc/kadm5.keytab
max_renewable_life = 7d 0h 0m 0s
default_principal_flags = +renewable 
supported_enctypes = aes128-cts:normal des3-hmac-sha1:normal arcfour-hmac:normal des-hmac-sha1:normal des-cbc-md5:normal des-cbc-crc:normal
}

#log path
[logging]
 default = FILE:/var/log/krb5/krb5libs.log
 kdc = FILE:/var/log/krb5/krb5kdc.log
 admin_server = FILE:/var/log/krb5/kadmind.log


4.2.3修改kerberos客户端配置文件
vi /etc/krb5.conf

[libdefaults]
 default_realm = AAS.COM    ##默认域
 dns_lookup_realm = true   ##false 时CM自动生成keytab失败
 dns_lookup_kdc = true
 ticket_lifetime = 24h
 renew_lifetime = 7d
 forwardable = true

#注意的是node1是你kdc服务的主机host
#作用域一般一个集群配一个足矣
[realms]
 AAS.COM = {
  kdc = cloudera03.AAS.com
  admin_server = cloudera03.AAS.com
 }

[domain_realm]
 .AAS.com = AAS.COM
 AAS.com = AAS.COM 

4.2.4修改/var/kerberos/krb5kdc/kadm5.acl配置
vi /var/kerberos/krb5kdc/kadm5.acl
#/admin结尾的都是带有管理权限的principal
*/admin@ AAS.COM    *
4.2.5 初始化Kerberos database
默认数据库路径为/var/kerberos/krb5kdc
$kdb5_util create –r AAS.COM -s   
初始化密码为AAS@123;
创建管理员账号
kadmin.local
#然后输入 
addprinc admin/admin@AAS.COM
#管理员密码为:kerberos
#提示 created关键字之后，输入 exit退出
exit 
配置kerberos启动项
chkconfig krb5kdc on
chkconfig kadmin on
service krb5kdc start
service kadmin start
测试管理员账号
Kinit  admin/admin 
Klist

4.2.6其他节点安装kerbetros客户端
yum -y install krb5-libs krb5-workstation 
复制/etc/krb5.conf 到各个客户端节点

4.3 KDC高可用部署
在cloudera02备节点安装Kerberos服务
yum -y install krb5-server krb5-libs krb5-auth-dialog krb5-workstation
注意：此处只安装服务，暂不做相应配置及启动服务。

主节点操作
修改/etc/krb5.conf 文件
#修改域部分,添加备节点
[realms]
  AAS.COM = {
  kdc = cloudera03.AAS.com
  admin_server = cloudera03.AAS.com
  default_realm = AAS.COM
kdc = cloudera02.AAS.com
 }

重启主节点的kdc服务
service krb5kdc restart
service kadmin restart

创建主机账号，并为账号生成keytab文件
kadmin.local
kadmin.local:  addprinc -randkey host/cloudera03.AAS.com
kadmin.local:  addprinc -randkey host/cloudera02.AAS.com
kadmin.local:  
kadmin.local:  ktadd host/cloudera03.AAS.com
kadmin.local:  ktadd host/cloudera02.AAS.com

复制以下文件到从Kerberos服务器相应目录
scp /etc/krb5.conf root@cloudera02.AAS.com:/etc/
scp /etc/krb5.keytab root@cloudera02.AAS.com:/etc/
scp /var/kerberos/krb5kdc/.k5.AAS.COM root@cloudera02.AAS.com:/var/kerberos/krb5kdc/
scp /var/kerberos/krb5kdc/kadm5.acl root@cloudera02.AAS.com:/var/kerberos/krb5kdc/
scp /var/kerberos/krb5kdc/kdc.conf  root@cloudera02.AAS.com: /var/kerberos/krb5kdc/

配置从节点
在从节点创建文件/var/kerberos/krb5kdc/kpropd.acl，配置文件中添加对应账户

host/cloudera03.AAS.com@AAS.COM
host/cloudera02.AAS.com@AAS.COM

添加如下信息到/etc/inetd.conf
krb5_prop stream tcp nowait root /usr/sbin/kpropd kpropd

添加如下信息到/etc/services
krb5_prop       754/tcp               # Kerberos replica propagation

从节点启动kpropd进程
$service kprop  start 
$chkconfig  kprop  on

平时 –分
将主节点数据同步到从节点
在主节点执行
$kdb5_util dump /var/kerberos/krb5kdc/master.dump
$kprop -f /var/kerberos/krb5kdc/master.dump   -d cloudera02.AAS.com
32768 bytes sent.
45389 bytes sent.
Database propagation to cloudera02.AAS.com: SUCCEEDED
显示数据传输完成。

启动从节点KDC进程
service krb5kdc  start
主节点数据自动同步到从节点
vim kprop_sync.sh
#!/bin/bash
source /etc/profile
echo "开始dump数据库文件"
DUMP=/var/kerberos/krb5kdc/master.dump
PORT=754
SLAVE="cloudera03.AAS.com"
TIMESTAMP=`date`
echo "Start at $TIMESTAMP"
kdb5_util dump $DUMP
kprop -f $DUMP -d -P $PORT $SLAVE

主节点数据灭分钟同步一次到从节点
crontab -e
#每分钟同步一次
* * * * * sh /var/kerberos/krb5kdc/kprop_sync.sh > /var/kerberos/krb5kdc/lastupdate
:wq

同步数据调试命令
备节点：
env KRB5_TRACE=/dev/stdout kpropd
主节点:
env KRB5_TRACE=/dev/stdout kdb5_util dump /var/kerberos/krb5kdc/master.dump
env KRB5_TRACE=/dev/stdout kprop -f /var/kerberos/krb5kdc/master.dump   -d cloudera03.AAS.com

4.4 Kerberos主备切换
将旧Master的数据手动同步到到其他从节点
$kdb5_util dump /var/kerberos/krb5kdc/master.dump
$kprop -f /var/kerberos/krb5kdc/master.dump   -d cloudera02.AAS.com

旧主节点准备kpropd.acl文件
启动kpropd进程
$kpropd

删除原备节点的kpropd.acl文件
cd /var/kerberos/krb5kdc
mv kpropd.acl kpropd.acl-back
修改/etc/krb5.conf，其中KDC的顺序调整，kerberos默认访问第一个KDC进行认证服务
[realms]
AAS.COM = {
  kdc = cloudera02.AAS.com
  kdc = cloudera03.AAS.com
  admin_server = cloudera02.AAS.com
  default_realm = AAS.COM
 }

在cloudera02节点启动kadmin进程
$service  kadmin  start 


4.5 Cloudera 集成Kerberos
创建Cloudera kerberos管理员账户
#在KDC中给Cloudera Manager添加管理员账号
#在KDC服务所在的机器操作
kadmin.local
addprinc cloudera-scm/admin@AAS.COM
#密码:AAS@123
添加其他账户：
addprinc    hive
addprinc    impala
addprinc    hdfs
addprinc    tpc
Cloudera 安全向导启用Kerberos
注意：不要使用Use Default Kerberos Principals
Kerberos 添加测试账户：
kadmin.local
addprinc  test

Cloudera 自动生成 CDHkeytab文件


4.6 Sentry 部署
4.6.1 安装Sentry服务
创建Sentry元数据库
CREATE DATABASE sentry DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;
GRANT ALL ON sentry.* TO 'root'@'%' IDENTIFIED BY 'AAS';
参照官网文档，在CDH启用Sentry。
4.6.2 Hive/impala 启用Sentry
启用Sentry
4.6.3 HDFS启用Sentry同步
HDFS 开启权限验证模式；
开启HDFS 的 Sentry同步


4.7 在Sentry中初始化hive数据管理员权限

用hive账户登录hive
初始化ktg
kinit   hive  
登录Hive
beeline -u "jdbc:hive2://172.19.2.186:10000/default;principal=hive/cloudera03.AAS.com@AAS.COM"
这里的 principal 是固定不变的，其指的 hive 服务所对应的 principal ，而不是用户所对应的 principal 。
执行授权命令
create  role admin_role;      #管理员角色
#指定hive数据库的权限管理员
grant all on server server1 to role admin_role;
grant role admin_role to group `hive`;
grant role admin_role to group `impala`;
grant role admin_role to group `hdfs`;

4.8 添加新用户并授权
创建tpc账户用于tpc测试
在cloudera03 创建本地用户tpc:tpc
新用户在KDC注册
kadmin.local -q ' addprinc  tpc'
为新用户授予tpc数据库的操作权限
以hive账户登录hive，执行命令
create  role tpctest_role;      #创建角色
grant all on database  tpcds_parquet  to  role tpctest_role;     #为角色授权
grant role tpctest_role to group `tpc`;      #将权限授予对应的用户组
show role grant group tpc;              #检查授权结果
登录测试：
kinit  tpc  
#登录Hive
beeline -u "jdbc:hive2://172.19.2.186:10000/default;principal=hive/cloudera03.AAS.com@AAS.COM"
0: jdbc:hive2://172.19.2.186:10000/default> show  databases;
+----------------+
| database_name  |
+----------------+
| default        |
| tpcds_parquet  |
+----------------+
2 rows selected (0.34 seconds)
4.9 为HDFS目录授权
先在HDFS中将需要授权的路径添加到Sentry同步路径集中。
create  role tpc_hdfs_role;
grant all on uri   '/tpc' to role tpc_hdfs_role;
grant role tpc_hdfs_role to group `tpc`;
Sentry对 HDFS目录的授权仅对HiveSQL有效，可用于控制Hive外部表权限，且授权成功后，即使在Sentry中解除这种授权，HiveSQL任然可以访问这些数据。

4.10 Hue中进行授权
Hue中授权是以Hue中的账户列表为基础了，这些账号与Linux系统账号对应。但是Hue不能自动识别Linux的账号。Hue通过识别Linux系统的用户信息，查找用户与用户组的对应关系。
需要在Hue中手动创建与Linux账户对应的Hue账号。然后再以特定的账号登录系统进行授权操作。


5 LDAP集成部署
openLDAP常用名词解释:
   o– organization（组织-公司）
   ou – organization unit（组织单元/部门）
   c - countryName（国家）
   dc - domainComponent（域名组件）
   sn – suer name（真实名称）
cn - common name（常用名称）
dn - distinguished name（专有名称）
5.1 LDAP本地安装
参考链接; https://blog.csdn.net/dockj/article/details/82392263
https://www.sohu.com/a/284300312_283613
https://www.cnblogs.com/duaner92/p/9931156.html
安装参考:
https://blog.csdn.net/dengchenrong/article/details/88389947

管理员dc组织：
com  AAS  admin
用户：
com AAS Users
用户组：
com  AAS  Group 
在cloudera01节点安装openLDAP
yum -y install openldap openldap-clients openldap-servers
检查版本信息
lapd –VV
@(#) $OpenLDAP: slapd 2.4.44 (Jan 29 2019 17:42:45) $
        mockbuild@x86-01.bsys.centos.org:/builddir/build/BUILD/openldap-2.4.44/openldap-2.4.44/servers/slapd
修改管理员密码
slappasswd  -s AAS@123
{SSHA}pzsWDd6grmlog23Im6PDEIO0lGF3Z2Z6

修改olcDatabase={2}hdb.ldif文件
修改olcDatabase={2}hdb.ldif文件,对于该文件增加root账户信息
# AUTO-GENERATED FILE - DO NOT EDIT!! Use ldapmodify.
# CRC32 1683967e
dn: olcDatabase={2}hdb
objectClass: olcDatabaseConfig
objectClass: olcHdbConfig
olcDatabase: {2}hdb
olcDbDirectory: /var/lib/ldap
#增加admin账户域前缀
olcSuffix: dc=AAS,dc=com
#管理员账户
olcRootDN: cn=admin,dc=AAS,dc=com
#管理员密码
olcRootPW: {SSHA}pzsWDd6grmlog23Im6PDEIO0lGF3Z2Z6
olcDbIndex: objectClass eq,pres
olcDbIndex: ou,cn,mail,surname,givenname eq,pres,sub
structuralObjectClass: olcHdbConfig
entryUUID: 02a64522-6feb-103a-971b-37eb88ab11a1
creatorsName: cn=config
createTimestamp: 20200811065247Z
entryCSN: 20200811065247.666681Z#000000#000#000000
modifiersName: cn=config
modifyTimestamp: 20200811065247Z

修改olcDatabase={1}monitor.ldif文件，增加管理员信息
# AUTO-GENERATED FILE - DO NOT EDIT!! Use ldapmodify.
# CRC32 87e34df8
dn: olcDatabase={1}monitor
objectClass: olcDatabaseConfig
olcDatabase: {1}monitor
#访问目录，添加管理员信息
olcAccess: {0}to * by dn.base="gidNumber=0+uidNumber=0,cn=peercred,cn=extern
 al,cn=auth" read by dn.base="cn=admin,dc=AAS,dc=com" read by * none
structuralObjectClass: olcDatabaseConfig
entryUUID: 02a63de8-6feb-103a-971a-37eb88ab11a1
creatorsName: cn=config
createTimestamp: 20200811065247Z
entryCSN: 20200811065247.666496Z#000000#000#000000
modifiersName: cn=config
modifyTimestamp: 20200811065247Z


验证配置是否准确
slaptest –u
5f3265a1 ldif_read_file: checksum error on "/etc/openldap/slapd.d/cn=config/olcDatabase={1}monitor.ldif"
5f3265a1 ldif_read_file: checksum error on "/etc/openldap/slapd.d/cn=config/olcDatabase={2}hdb.ldif"
config file testing succeeded

启动OpenLDAP服务
//开始ldap
systemctl enable slapd
//启动ldap
systemctl start slapd
//查看ldap的状态
systemctl status slapd

配置OpenLDAP数据库

上传kerber相关schema
kerberos.openldap.ldif
kerberos.schema
加载schema，编辑配置文件，添加如下信息
ldapadd -Q -Y EXTERNAL -H ldapi:/// -f  /etc/openldap/schema/core.ldif
ldapadd -Q -Y EXTERNAL -H ldapi:/// -f  /etc/openldap/schema/corba.ldif
ldapadd -Q -Y EXTERNAL -H ldapi:/// -f  /etc/openldap/schema/cosine.ldif
ldapadd -Q -Y EXTERNAL -H ldapi:/// -f  /etc/openldap/schema/dyngroup.ldif
ldapadd -Q -Y EXTERNAL -H ldapi:/// -f  /etc/openldap/schema/inetorgperson.ldif
ldapadd -Q -Y EXTERNAL -H ldapi:/// -f  /etc/openldap/schema/java.ldif
ldapadd -Q -Y EXTERNAL -H ldapi:/// -f  /etc/openldap/schema/kerberos.openldap.ldif
ldapadd -Q -Y EXTERNAL -H ldapi:/// -f  /etc/openldap/schema/misc.ldif
ldapadd -Q -Y EXTERNAL -H ldapi:/// -f  /etc/openldap/schema/nis.ldif
ldapadd -Q -Y EXTERNAL -H ldapi:/// -f  /etc/openldap/schema/openldap.ldif
ldapadd -Q -Y EXTERNAL -H ldapi:/// -f  /etc/openldap/schema/ppolicy.ldif
ldapadd -Q -Y EXTERNAL -H ldapi:/// -f  /etc/openldap/schema/collective.ldif
ldapadd -Q -Y EXTERNAL -H ldapi:/// -f  /etc/openldap/schema/duaconf.ldif
ldapadd -Q -Y EXTERNAL -H ldapi:/// -f  /etc/openldap/schema/pmi.ldif
初始化管理员账户
配置init_admin.ldif
dn: dc=AAS,dc=com
objectClass: top
objectClass: dcObject
objectclass: organization
o: AAS.com
dc: AAS

dn: ou=Users,dc=AAS,dc=com
objectClass: organizationalUnit
ou: users

dn: ou=group,dc=AAS,dc=com
objectClass: organizationalUnit
ou: group

dn: cn=admin,dc=AAS,dc=com
objectClass: organizationalRole
cn: admin
description: Directory Administrator

$ ldapadd  -x -D cn=admin,dc=AAS,dc=com -W -f init_admin.ldif
Enter LDAP Password:
adding new entry "dc=AAS,dc=com"
adding new entry "ou=Users,dc=AAS,dc=com"
adding new entry "ou=group,dc=AAS,dc=com"
adding new entry "cn=admin,dc=AAS,dc=com"

修改日志配置级别
dn: cn=config
changetype: modify
add: olcLogLevel
olcLogLevel: 32

$ldapmodify -Y EXTERNAL -H ldapi:/// -f log.ldif
SASL/EXTERNAL authentication started
SASL username: gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth
SASL SSF: 0
modifying entry "cn=config"

执行如下命令
mkdir -p /var/log/slapd
chown ldap:ldap /var/log/slapd/
vim /etc/rsyslog.conf
echo "local4.* /var/log/slapd/slapd.log" >> /etc/rsyslog.conf
systemctl restart rsyslog
systemctl restart slapd

5.2本地账户导入到LDAP
安装工具
yum install migrationtools -y
修改默认域/usr/share/migrationtools/migrate_common.ph
# Default DNS domain
$DEFAULT_MAIL_DOMAIN = "AAS.com";
# Default base
$DEFAULT_BASE = "dc=AAS,dc=com";

导出账户信息
cat /etc/passwd > people
cat /etc/group > group

使用migrationtools工具生成用户和组ldif文件
/usr/share/migrationtools/migrate_passwd.pl people people.ldif
/usr/share/migrationtools/migrate_group.pl group group.ldif
注意：这里people.ldif文件中，user的默认组织是People，需要改成与当前系统匹配的User
如：
dn: uid=tpc,ou=Users,dc=AAS,dc=com

导入到LDAP中
ldapadd -x -W -D "cn=admin,dc=AAS,dc=com" -f people.ldif
ldapadd -x -W -D "cn=admin,dc=AAS,dc=com" -f group.ldif

查看导入结果
ldapsearch -x -H ldap://172.19.2.184:389 -b ou=Group,dc=AAS,dc=com
ldapsearch -x -H ldap://172.19.2.184:389 -b ou=users,dc=AAS,dc=com

5.3 Hue集成LDAP测试
配置Hue的LDAP参数:
backend: desktop.auth.backend.LdapBackend
ldap_url: ldap://cloudera01.AAS.com:389
ldap_username_pattern: uid=<username>,ou=Users,dc=AAS,dc=com
create_users_on_login: true
search_bind_authentication: true
base_dn: dc=AAS,dc=com
bind_dn: cn=admin,dc=AAS,dc=com
bind_password: AAS@123
user_name_attr: uid
group_name_attr: cn
配置相关参数后重新启动Hue
在LDAP中创建账户hueldap4/hueldap.
可以直接登录为Hue普通用户。


