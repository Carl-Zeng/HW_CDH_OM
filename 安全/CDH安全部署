方案内容：
1 CDH数据安全方案设计
2 数据安全方案实施
3 数据权限划分要点
4 安全方案实施对现有集群的影响
5 安全方案的运维
6 其他可能的安全需求

1 方案准备说明
方案基于CD6.3进行设计；原则上以实现数据授权为目标，兼顾运维需求。
前置条件：
1）	因为是内网，可以不做通信加密（TSL）；
2）	在满足基本权限要求的前提下，可以考虑使用LDAP做用户管理。
3）	可以考虑使用集成的开源工具，如FreeIPA。
2 安全方案需求
1）	实现细粒度的权限管控；
2）	数据对象的通配符筛选；
3）	CDH数据接口尽可能覆盖；
4）	合理的运维操作与支持；
5）	体系的高可用性；
3 安全方案设计
3.1 方案设计
采用MIT Kerberos + Sentry + openLADP 方案。Kerberos实现所用用户以及服务间的身份认证，LDAP实现用户管理，Sentry用来做授权。
3.2 高可用设计
Sentry本身支持高可用部署，可以部署两个Sentry Server；
KDC也支持主备部署，安装时默认采用2分钟的同步间隔。多个KDC可同时作为备份，当MasterKDC 失败后，从KDC将自动提供认证服务，此时对已有的账户认证不受影响，但是不能做新增操作。
所有对KDC的所作都记录在MasterKDC节点，这个操作需要手动同步到其他从KDC节点。
Kadmin进程提供了远程kadmin服务，若此服务失败，不能通过管理客户端kadmin进行管理命令操作，但是仍然可以在Master本地启动kadmin.local 进程进行操作，同时，数据会直接写入本地数据库文件中，不受krb5kdc进程影响。  

3.3安全方案对现有HDFS的影响
1）采用安全方案时，HDFS开启权限认证模式，访问HDFS文件需要匹配HDFS的访问控制权限。
2）Sentry会同步当前HDFS的ACL信息，
Sentry权限设计只对HiveSQL/impala有效， Sentry也可以对HDFS特定目录生效（对Hive SQL生效，通过其他方式访问HDFS目录的，只能通过HDFS ACL配置权限）。
3）所有的客户端访问HDFS/Hive/impala时需要提前初始化kerberos票据。
4）Sentry授权只能对用户组授权，授权最细粒度为列Column。
5）Hue的用户与Linux用户是按名称对应的，但是需要手动创建，不能自动识别。
6）所有的Hadoop客户端都需要做Kerberos适配。

4 安全方案部署实施
4.1 测试环境 
准备测试账户
Kerberos 管理账号：admin ： AAS@123
Cloudera Kerberos管理员账号：  cloudera-scm  :  AAS@123
HDFS超级账户：hdfs：hdfs
Hive超级账户： hvie：hive
Impala超级账户：impala：impala
测试账号;  tpc ： tpc
测试环境地址
CDH 地址：http://172.19.2.184:7180/cmf/home
Kerberos 地址： Master: cloudera02.AAS.com   备：cloudera03.AAS.com
OpenLDAP地址：cloudera01.AAS.com
4.2 Kerberos部署
参考文档
安装链接:
https://www.jianshu.com/p/544aeacc803b
排错链接;
https://www.cnblogs.com/barneywill/p/10398663.html
参数解释
https://www.cnblogs.com/wn1m/p/10700466.html
4.2.1 在cloudera03节点部署KDC
##执行命令
yum -y install krb5-server krb5-libs krb5-auth-dialog1 krb5-workstation
4.2.2配置kdc.conf 文件/var/kerberos/krb5kdc/kdc.conf
vi /var/kerberos/krb5kdc/kdc.conf
[kdcdefaults]
kdc_ports = 88
kdc_tcp_ports = 88
[realms]
AAS.COM = {
#master_key_type = aes256-cts
acl_file = /var/kerberos/krb5kdc/kadm5.acl
dict_file = /usr/share/dict/words
admin_keytab = /var/kerberos/krb5kdc/kadm5.keytab
max_renewable_life = 7d 0h 0m 0s
default_principal_flags = +renewable 
supported_enctypes = aes128-cts:normal des3-hmac-sha1:normal arcfour-hmac:normal des-hmac-sha1:normal des-cbc-md5:normal des-cbc-crc:normal
}

#log path
[logging]
 default = FILE:/var/log/krb5/krb5libs.log
 kdc = FILE:/var/log/krb5/krb5kdc.log
 admin_server = FILE:/var/log/krb5/kadmind.log


4.2.3修改kerberos客户端配置文件
vi /etc/krb5.conf

[libdefaults]
 default_realm = AAS.COM    ##默认域
 dns_lookup_realm = true   ##false 时CM自动生成keytab失败
 dns_lookup_kdc = true
 ticket_lifetime = 24h
 renew_lifetime = 7d
 forwardable = true

#注意的是node1是你kdc服务的主机host
#作用域一般一个集群配一个足矣
[realms]
 AAS.COM = {
  kdc = cloudera03.AAS.com
  admin_server = cloudera03.AAS.com
 }

[domain_realm]
 .AAS.com = AAS.COM
 AAS.com = AAS.COM 

4.2.4修改/var/kerberos/krb5kdc/kadm5.acl配置
vi /var/kerberos/krb5kdc/kadm5.acl
#/admin结尾的都是带有管理权限的principal
*/admin@ AAS.COM    *
4.2.5 初始化Kerberos database
默认数据库路径为/var/kerberos/krb5kdc
$kdb5_util create –r AAS.COM -s   
初始化密码为AAS@123;
创建管理员账号
kadmin.local
#然后输入 
addprinc admin/admin@AAS.COM
#管理员密码为:kerberos
#提示 created关键字之后，输入 exit退出
exit 
配置kerberos启动项
chkconfig krb5kdc on
chkconfig kadmin on
service krb5kdc start
service kadmin start
测试管理员账号
Kinit  admin/admin 
Klist

4.2.6其他节点安装kerbetros客户端
yum -y install krb5-libs krb5-workstation 
复制/etc/krb5.conf 到各个客户端节点

4.3 KDC高可用部署
在cloudera02备节点安装Kerberos服务
yum -y install krb5-server krb5-libs krb5-auth-dialog krb5-workstation
注意：此处只安装服务，暂不做相应配置及启动服务。

主节点操作
修改/etc/krb5.conf 文件
#修改域部分,添加备节点
[realms]
  AAS.COM = {
  kdc = cloudera03.AAS.com
  admin_server = cloudera03.AAS.com
  default_realm = AAS.COM
kdc = cloudera02.AAS.com
 }

重启主节点的kdc服务
service krb5kdc restart
service kadmin restart

创建主机账号，并为账号生成keytab文件
kadmin.local
kadmin.local:  addprinc -randkey host/cloudera03.AAS.com
kadmin.local:  addprinc -randkey host/cloudera02.AAS.com
kadmin.local:  
kadmin.local:  ktadd host/cloudera03.AAS.com
kadmin.local:  ktadd host/cloudera02.AAS.com

复制以下文件到从Kerberos服务器相应目录
scp /etc/krb5.conf root@cloudera02.AAS.com:/etc/
scp /etc/krb5.keytab root@cloudera02.AAS.com:/etc/
scp /var/kerberos/krb5kdc/.k5.AAS.COM root@cloudera02.AAS.com:/var/kerberos/krb5kdc/
scp /var/kerberos/krb5kdc/kadm5.acl root@cloudera02.AAS.com:/var/kerberos/krb5kdc/
scp /var/kerberos/krb5kdc/kdc.conf  root@cloudera02.AAS.com: /var/kerberos/krb5kdc/

配置从节点
在从节点创建文件/var/kerberos/krb5kdc/kpropd.acl，配置文件中添加对应账户

host/cloudera03.AAS.com@AAS.COM
host/cloudera02.AAS.com@AAS.COM

添加如下信息到/etc/inetd.conf
krb5_prop stream tcp nowait root /usr/sbin/kpropd kpropd

添加如下信息到/etc/services
krb5_prop       754/tcp               # Kerberos replica propagation

从节点启动kpropd进程
$service kprop  start 
$chkconfig  kprop  on

平时 –分
将主节点数据同步到从节点
在主节点执行
$kdb5_util dump /var/kerberos/krb5kdc/master.dump
$kprop -f /var/kerberos/krb5kdc/master.dump   -d cloudera02.AAS.com
32768 bytes sent.
45389 bytes sent.
Database propagation to cloudera02.AAS.com: SUCCEEDED
显示数据传输完成。

启动从节点KDC进程
service krb5kdc  start
主节点数据自动同步到从节点
vim kprop_sync.sh
#!/bin/bash
source /etc/profile
echo "开始dump数据库文件"
DUMP=/var/kerberos/krb5kdc/master.dump
PORT=754
SLAVE="cloudera03.AAS.com"
TIMESTAMP=`date`
echo "Start at $TIMESTAMP"
kdb5_util dump $DUMP
kprop -f $DUMP -d -P $PORT $SLAVE

主节点数据灭分钟同步一次到从节点
crontab -e
#每分钟同步一次
* * * * * sh /var/kerberos/krb5kdc/kprop_sync.sh > /var/kerberos/krb5kdc/lastupdate
:wq

同步数据调试命令
备节点：
env KRB5_TRACE=/dev/stdout kpropd
主节点:
env KRB5_TRACE=/dev/stdout kdb5_util dump /var/kerberos/krb5kdc/master.dump
env KRB5_TRACE=/dev/stdout kprop -f /var/kerberos/krb5kdc/master.dump   -d cloudera03.AAS.com

4.4 Kerberos主备切换
将旧Master的数据手动同步到到其他从节点
$kdb5_util dump /var/kerberos/krb5kdc/master.dump
$kprop -f /var/kerberos/krb5kdc/master.dump   -d cloudera02.AAS.com

旧主节点准备kpropd.acl文件
启动kpropd进程
$kpropd

删除原备节点的kpropd.acl文件
cd /var/kerberos/krb5kdc
mv kpropd.acl kpropd.acl-back
修改/etc/krb5.conf，其中KDC的顺序调整，kerberos默认访问第一个KDC进行认证服务
[realms]
AAS.COM = {
  kdc = cloudera02.AAS.com
  kdc = cloudera03.AAS.com
  admin_server = cloudera02.AAS.com
  default_realm = AAS.COM
 }

在cloudera02节点启动kadmin进程
$service  kadmin  start 


4.5 Cloudera 集成Kerberos
创建Cloudera kerberos管理员账户
#在KDC中给Cloudera Manager添加管理员账号
#在KDC服务所在的机器操作
kadmin.local
addprinc cloudera-scm/admin@AAS.COM
#密码:AAS@123
添加其他账户：
addprinc    hive
addprinc    impala
addprinc    hdfs
addprinc    tpc
Cloudera 安全向导启用Kerberos
注意：不要使用Use Default Kerberos Principals
Kerberos 添加测试账户：
kadmin.local
addprinc  test

Cloudera 自动生成 CDHkeytab文件


4.6 Sentry 部署
4.6.1 安装Sentry服务
创建Sentry元数据库
CREATE DATABASE sentry DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;
GRANT ALL ON sentry.* TO 'root'@'%' IDENTIFIED BY 'AAS';
参照官网文档，在CDH启用Sentry。
4.6.2 Hive/impala 启用Sentry
启用Sentry
4.6.3 HDFS启用Sentry同步
HDFS 开启权限验证模式；
开启HDFS 的 Sentry同步


4.7 在Sentry中初始化hive数据管理员权限

用hive账户登录hive
初始化ktg
kinit   hive  
登录Hive
beeline -u "jdbc:hive2://172.19.2.186:10000/default;principal=hive/cloudera03.AAS.com@AAS.COM"
这里的 principal 是固定不变的，其指的 hive 服务所对应的 principal ，而不是用户所对应的 principal 。
执行授权命令
create  role admin_role;      #管理员角色
#指定hive数据库的权限管理员
grant all on server server1 to role admin_role;
grant role admin_role to group `hive`;
grant role admin_role to group `impala`;
grant role admin_role to group `hdfs`;

4.8 添加新用户并授权
创建tpc账户用于tpc测试
在cloudera03 创建本地用户tpc:tpc
新用户在KDC注册
kadmin.local -q ' addprinc  tpc'
为新用户授予tpc数据库的操作权限
以hive账户登录hive，执行命令
create  role tpctest_role;      #创建角色
grant all on database  tpcds_parquet  to  role tpctest_role;     #为角色授权
grant role tpctest_role to group `tpc`;      #将权限授予对应的用户组
show role grant group tpc;              #检查授权结果
登录测试：
kinit  tpc  
#登录Hive
beeline -u "jdbc:hive2://172.19.2.186:10000/default;principal=hive/cloudera03.AAS.com@AAS.COM"
0: jdbc:hive2://172.19.2.186:10000/default> show  databases;
+----------------+
| database_name  |
+----------------+
| default        |
| tpcds_parquet  |
+----------------+
2 rows selected (0.34 seconds)
4.9 为HDFS目录授权
先在HDFS中将需要授权的路径添加到Sentry同步路径集中。
create  role tpc_hdfs_role;
grant all on uri   '/tpc' to role tpc_hdfs_role;
grant role tpc_hdfs_role to group `tpc`;
Sentry对 HDFS目录的授权仅对HiveSQL有效，可用于控制Hive外部表权限，且授权成功后，即使在Sentry中解除这种授权，HiveSQL任然可以访问这些数据。

4.10 Hue中进行授权
Hue中授权是以Hue中的账户列表为基础了，这些账号与Linux系统账号对应。但是Hue不能自动识别Linux的账号。Hue通过识别Linux系统的用户信息，查找用户与用户组的对应关系。
需要在Hue中手动创建与Linux账户对应的Hue账号。然后再以特定的账号登录系统进行授权操作。



